{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "322290e0",
   "metadata": {},
   "source": [
    "# Split between languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be229a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69147b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/en/train.jsonl\n",
      "data/zh/train.jsonl\n",
      "data/zh/test.jsonl\n"
     ]
    }
   ],
   "source": [
    "languages = [\"en\",\"zh\"]\n",
    "\n",
    "def read_files_and_split(languages):\n",
    "    src_lang_path = languages[0]+\"_formats.json\"\n",
    "    src_lang_path = os.path.join(\"templates\", src_lang_path)\n",
    "    src_json = pd.read_json(src_lang_path)\n",
    "    tgt_lang_path = languages[1]+\"_formats.json\"\n",
    "    tgt_lang_path = os.path.join(\"templates\", tgt_lang_path)\n",
    "    tgt_json = pd.read_json(tgt_lang_path)\n",
    "\n",
    "    path = os.path.join(\"data\", \"people.csv\")\n",
    "    src_lang_train = pd.read_csv(path)\n",
    "\n",
    "    tgt_lang_train, tgt_lang_test = train_test_split(src_lang_train, test_size=0.5, random_state=42)\n",
    "\n",
    "    return src_json, tgt_json, src_lang_train, tgt_lang_train, tgt_lang_test\n",
    "\n",
    "\n",
    "\n",
    "def fill_the_templates(dataframe, template_json, language, typ):\n",
    "    dir = os.path.join(\"data\", language)\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    path = os.path.join(dir, f\"{typ}.jsonl\") \n",
    "\n",
    "    print(path)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for person in dataframe.iterrows():\n",
    "            for key in template_json.keys():\n",
    "                for value in template_json[key]:\n",
    "                    dictr = {}\n",
    "                    question = value[\"question\"]\n",
    "                    answer = value[\"answer\"]\n",
    "                    question = question.replace(\"{name}\", person[1][\"name\"])\n",
    "                    answer = answer.replace(\"{name}\", person[1][\"name\"])\n",
    "                    if key ==\"Place of living\":\n",
    "                        answer = answer.replace(\"{location}\", person[1][\"city\"])\n",
    "                    if key==\"Birth\":\n",
    "                        answer = answer.replace(\"{date}\", str(person[1][\"birth_date\"]))\n",
    "                    if key==\"Death\":\n",
    "                        answer = answer.replace(\"{date}\", str(person[1][\"death_date\"]))\n",
    "                    dictr[\"prompt\"] = question\n",
    "                    dictr[\"answer\"] = answer\n",
    "                    outfile.write(json.dumps(dictr, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "src_json, tgt_json, src_lang_train, tgt_lang_train, tgt_lang_test = read_files_and_split(languages)\n",
    "fill_the_templates(src_lang_train, src_json, languages[0], \"train\")\n",
    "fill_the_templates(tgt_lang_train, tgt_json, languages[1], \"train\")\n",
    "fill_the_templates(tgt_lang_test, tgt_json, languages[1], \"test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge_extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
